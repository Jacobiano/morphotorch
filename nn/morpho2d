
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Optional

#import lietorch 
#!pip install lietorch
#from lietorch.generic import grayscale_dilation_2d

#I think that is an slow implementation based on channelwise dilation.

def dilation2D(x,kernel):
  #Channelwise Dilation (Marginal)
  se_h, se_w = kernel.shape[-2],kernel.shape[-1]
  origin = [se_h // 2, se_w // 2]
  # pad
  pad_e: List[int] = [origin[1], se_w - origin[1] - 1, origin[0], se_h - origin[0] - 1]
  border_value = -1e4
  border_type = 'constant'
  output = F.pad(x, pad_e, mode=border_type, value=border_value)
  output = output.unfold(2, se_h, 1).unfold(3, se_w, 1)
  output, _ = torch.max(output + kernel, 4)
  output, _ = torch.max(output, 4)
  return output

def erosion2D(image,SE):
   return -dilation2D(-image, torch.flip(SE,[5,4])) #B,C,W1,W2,h,w

class DilationLayer(nn.Module):
    """ DilationLayer """
    def __init__(self, input_dim,kernel_size):
        super().__init__()
        struct_element = torch.Tensor(1,input_dim,1,1,kernel_size[0],kernel_size[1]) #B,C,W1,W2,h,w
        self.struct_element = nn.Parameter(struct_element)

        # initialize structuring element
        nn.init.uniform_(self.struct_element,a=-1.,b=0.) # weight init
        
    def forward(self, x):
        return dilation2D(x,self.struct_element)
    
class ErosionLayer(nn.Module):
    """ ErosionLayer """
    def __init__(self, input_dim,kernel_size):
        super().__init__()
        struct_element = torch.Tensor(1,input_dim,1,1,kernel_size[0],kernel_size[1]) #B,C,W1,W2,h,w
        self.struct_element = nn.Parameter(struct_element)

        # initialize structuring element
        nn.init.uniform_(self.struct_element,a=-1.,b=0.) # weight init
        
    def forward(self, x):
        return erosion2D(x,self.struct_element)



# def erosion2D(image,SE):
#   return -lietorch.generic.grayscale_dilation_2d(-image, torch.flip(SE,[1,0]))
# def dilation2D(image,SE):
#   return lietorch.generic.grayscale_dilation_2d(image, SE)

# channels_erosion2D=torch.vmap(erosion2D,in_dims=2,out_dims=2)
# channels_dilation2D=torch.vmap(dilation2D,in_dims=2,out_dims=2)

# class Dilation2DLayer(nn.Module):
#     """ Channelwise Dilation2D """
#     def __init__(self, channels, kernel_size):
#         super().__init__()
#         weights = torch.Tensor(kernel_size[0], kernel_size[1],channels)
#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.
#         nn.init.uniform_(self.weights, a=-1.0, b=0.0) # # initialize weights and biases
#     def forward(self, x):
#       result = torch.zeros([x.shape[0],x.shape[1],x.shape[2],x.shape[3]])
#       for i in range(x.shape[0]):
#         result[i,:,:,:]=channels_dilation2D(x[i,:,:,:], self.weights)
#       return result
# class Erosion2DLayer(nn.Module):
#     """ Channelwise Erosion2D """
#     def __init__(self, channels, kernel_size):
#         super().__init__()
#         weights = torch.Tensor(kernel_size[0], kernel_size[1],channels)
#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.
#         nn.init.uniform_(self.weights, a=-1.0, b=0.0) # # initialize weights and biases
#     def forward(self, x):
#       result = torch.zeros([x.shape[0],x.shape[1],x.shape[2],x.shape[3]])
#       for i in range(x.shape[0]):
#         result[i,:,:,:]=channels_erosion2D(x[i,:,:,:], self.weights)
#       return result
# class Opening2DLayer(nn.Module):
#     """ Channelwise Opening2D """
#     def __init__(self, channels, kernel_size):
#         super().__init__()
#         weights = torch.Tensor(kernel_size[0], kernel_size[1],channels)
#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.
#         nn.init.uniform_(self.weights, a=-1.0, b=0.0) # # initialize weights and biases
#     def forward(self, x):
#       result = torch.zeros([x.shape[0],x.shape[1],x.shape[2],x.shape[3]])
#       for i in range(x.shape[0]):
#         result[i,:,:,:]=channels_dilation2D(channels_erosion2D(x[i,:,:,:], self.weights),self.weights)
#       return result
# class Closing2DLayer(nn.Module):
#     """ Channelwise Closing2D """
#     def __init__(self, channels, kernel_size):
#         super().__init__()
#         weights = torch.Tensor(kernel_size[0], kernel_size[1],channels)
#         self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.
#         nn.init.uniform_(self.weights, a=-1.0, b=0.0) # # initialize weights and biases

#     def forward(self, x):
#       result = torch.zeros([x.shape[0],x.shape[1],x.shape[2],x.shape[3]])
#       for i in range(x.shape[0]):
#         result[i,:,:,:]=channels_erosion2D(channels_dilation2D(x[i,:,:,:], self.weights),self.weights)
#       return result